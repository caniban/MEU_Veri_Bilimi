{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri bilimi projelerinin ilk adımı, veriyi çalışma ortamımıza doğru şekilde aktarmaktır. Bu bölümde farklı formatlardaki (.txt, .csv, .xlsx, .sas, .mat) verileri ve internet üzerindeki kaynakları nasıl okuyacağımızı öğreneceğiz.\n",
    "\n",
    "Öncelikle çalışma klasörümüzde hangi dosyaların olduğuna bakalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'cars_train_annos.mat', 'coor.csv', 'credit.txt', 'lorem_ipsum.txt', 'mutluluk_indeksi.xlsx', 'netflix.csv', 'tax.dta', 'tax.sas7bdat', 'titanic.csv', 'traffic_density_202010.csv', 'unite 09 veri okuma.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Mevcut dizindeki dosyaları listeler\n",
    "print(os.listdir('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Düz Metin Dosyalarını Okuma (.txt)\n",
    "\n",
    "Metin dosyalarını okumanın en güvenli yolu `with` yapısını kullanmaktır. Bu yapı, işlem bittiğinde dosyanın otomatik olarak kapatılmasını garanti eder.\n",
    "\n",
    "Örnek: `lorem_ipsum.txt` dosyasını okuyalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc volutpat vestibulum turpis vitae eleifend. Nullam vitae sollicitudin erat, non interdum felis. Aenean fringilla nec orci eu eleifend. Suspendisse semper turpis nec libero finibus, eget viverra ante molestie. Proin quis pulvinar metus. Nunc tortor felis, faucibus ac purus eu, suscipit dictum dolor. Nullam vel mi sed nibh varius cursus.\n",
      "\n",
      "Phasellus aliquet nunc nec ex convallis tincidunt. Phasellus ac pretium massa. Aenean purus urna, egestas sit amet pharetra non, volutpat ut metus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi non mauris non mauris interdum eleifend. Cras ex purus, dignissim sit amet velit at, molestie scelerisque justo. Phasellus sit amet placerat lorem. Pellentesque sodales, lacus in cursus faucibus, nulla sem egestas nisl, sit amet molestie lorem nunc eget nibh. Vestibulum fringilla risus nec ipsum semper, fermentum facilisis eros aliquam. Nulla porttitor risus ut diam accumsan maximus at at sapien. Proin urna ante, tincidunt id turpis eu, venenatis auctor ipsum. Vivamus et orci elementum, faucibus orci id, malesuada justo.\n",
      "\n",
      "\n",
      "\n",
      "Dosya kapalı mı? True\n"
     ]
    }
   ],
   "source": [
    "# 'r' modu read (okuma) anlamına gelir.\n",
    "with open('lorem_ipsum.txt', 'r') as dosya:\n",
    "    icerik = dosya.read()\n",
    "    print(icerik)\n",
    "\n",
    "# Not: 'with' bloğundan çıktığımız an dosya otomatik kapanır.\n",
    "print(f\"\\nDosya kapalı mı? {dosya.closed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019', '2018']\n",
      "<class 'pandas.io.excel._base.ExcelFile'>\n"
     ]
    }
   ],
   "source": [
    "# pandas kütüphanesini yükleyelim.\n",
    "import pandas as pd\n",
    "\n",
    "# Dosya ismini belirleyelim.\n",
    "dosya = 'mutluluk_indeksi.xlsx'\n",
    "\n",
    "# Excel dosyasını yükleyerek xl veri dosyasını oluşturalım.\n",
    "xl = pd.ExcelFile(dosya)\n",
    "\n",
    "# Excel dosyası içinde kayıtlı olan hesap tablolarını (ayrı sekmeler halinde saklanır) ekrana verelim.\n",
    "print(xl.sheet_names)\n",
    "print(type(xl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dosyada ülkelerin mutluluk indeksi verileri hem 2019 hem de 2018 yılları için ayrı ayrı hesap tablosu sekmesinde saklanmaktadır. Bu her iki hesap tablosu için ayrı veri çerçeveleri oluşturabiliriz. Bunun için `.parse()` yöntemi kullanılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Overall rank Country or region  Score  GDP per capita  Social support  \\\n",
      "0             1           Finland   7769          1340.0          1587.0   \n",
      "1             2           Denmark   7600          1383.0          1573.0   \n",
      "2             3            Norway   7554          1488.0          1582.0   \n",
      "3             4           Iceland   7494          1380.0          1624.0   \n",
      "4             5       Netherlands   7488          1396.0          1522.0   \n",
      "\n",
      "   Healthy life expectancy  Freedom to make life choices  Generosity  \\\n",
      "0                    0.986                         0.596       0.153   \n",
      "1                    0.996                         0.592       0.252   \n",
      "2                 1028.000                         0.603       0.271   \n",
      "3                 1026.000                         0.591       0.354   \n",
      "4                    0.999                         0.557       0.322   \n",
      "\n",
      "   Perceptions of corruption  \n",
      "0                      0.393  \n",
      "1                      0.410  \n",
      "2                      0.341  \n",
      "3                      0.118  \n",
      "4                      0.298  \n"
     ]
    }
   ],
   "source": [
    "df1 = xl.parse('2019')\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.parse()` yönteminin içine hesap tablosunun ismini yazabileceğimiz gibi sıra numarasını (indeksini) de yazabiliriz. 2018 yılı için deneyelim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Overall rank Country or region  Score  GDP per capita  Social support  \\\n",
      "0             1           Finland   7632          1305.0          1592.0   \n",
      "1             2            Norway   7594          1456.0          1582.0   \n",
      "2             3           Denmark   7555          1351.0          1590.0   \n",
      "3             4           Iceland   7495          1343.0          1644.0   \n",
      "4             5       Switzerland   7487          1420.0          1549.0   \n",
      "\n",
      "   Healthy life expectancy  Freedom to make life choices  Generosity  \\\n",
      "0                    0.874                         0.681       0.202   \n",
      "1                    0.861                         0.686       0.286   \n",
      "2                    0.868                         0.683       0.284   \n",
      "3                    0.914                         0.677       0.353   \n",
      "4                    0.927                         0.660       0.256   \n",
      "\n",
      "   Perceptions of corruption  \n",
      "0                      0.393  \n",
      "1                      0.340  \n",
      "2                      0.408  \n",
      "3                      0.138  \n",
      "4                      0.357  \n"
     ]
    }
   ],
   "source": [
    "df2 = xl.parse(1)\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi ilk hesap tablosunu, `.parse()` yöntemi ile veri çerçevesi haline getirelim. İlk satırı atlayalım ve sütunları Türkçe'ye çevirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Genel Sıralama         Ülke  Skor  Kişi Başına Milli Gelir Puanı  \\\n",
      "0               2      Denmark  7600                         1383.0   \n",
      "1               3       Norway  7554                         1488.0   \n",
      "2               4      Iceland  7494                         1380.0   \n",
      "3               5  Netherlands  7488                         1396.0   \n",
      "4               6  Switzerland  7480                         1452.0   \n",
      "\n",
      "   Sosyal Destek Puanı  Sağlıklı Yaşam Beklentisi Puanı  \\\n",
      "0               1573.0                            0.996   \n",
      "1               1582.0                         1028.000   \n",
      "2               1624.0                         1026.000   \n",
      "3               1522.0                            0.999   \n",
      "4               1526.0                         1052.000   \n",
      "\n",
      "   Yaşam Tercihlerinde Özgürlük Puanı  Cömertlik Puanı  Yolsuzluk Algısı Puanı  \n",
      "0                               0.592            0.252                   0.410  \n",
      "1                               0.603            0.271                   0.341  \n",
      "2                               0.591            0.354                   0.118  \n",
      "3                               0.557            0.322                   0.298  \n",
      "4                               0.572            0.263                   0.343  \n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df1 = xl.parse(0, skiprows=[0], names=['Genel Sıralama','Ülke', 'Skor', 'Kişi Başına Milli Gelir Puanı', \n",
    "                                       'Sosyal Destek Puanı', 'Sağlıklı Yaşam Beklentisi Puanı', \n",
    "                                       'Yaşam Tercihlerinde Özgürlük Puanı', 'Cömertlik Puanı', 'Yolsuzluk Algısı Puanı'])\n",
    "print(df1.head())\n",
    "print(type(df1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web ortamındaki bağlantıları kullanarak da, Jupyter Notebook içerisine veri aktarımı yapmamız mümkündür. \n",
    "İstanbul Büyükşehir Belediyesi Açık Veri Portalı'ndan Ekim 2020 trafik verilerini kullanmak isteyelim.  (https://data.ibb.gov.tr/dataset/saatlik-trafik-yogunluk-veri-seti/resource/949d4a3b-91d2-4c56-b82f-4ef081e39c45)\n",
    "Bu sayfadaki verileri indirmeden, doğrudan bağlantı adresi alarak, veriyi çalışma ortamına eklememiz için `urllib.request` modülünün `urlretrieve` fonksiyonunu kullanabiliriz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('traffic_density_202010.csv', <http.client.HTTPMessage at 0x237058596d0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "url = 'https://data.ibb.gov.tr/dataset/3ee6d744-5da2-40c8-9cd6-0e3e41f1928f/resource/949d4a3b-91d2-4c56-b82f-4ef081e39c45/download/traffic_density_202010.csv'\n",
    "    \n",
    "urlretrieve(url, 'traffic_density_202010.csv') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             DATE_TIME   LATITUDE  LONGITUDE GEOHASH  MINIMUM_SPEED  \\\n",
      "0  2020-10-01 00:00:00  41.195984  28.767700  sxk6qe             18   \n",
      "1  2020-10-01 00:00:00  41.009216  29.042358  sxk9kc              9   \n",
      "2  2020-10-01 00:00:00  40.970764  29.075317  sxk9jd              9   \n",
      "3  2020-10-01 00:00:00  41.069641  28.888550  sxk99k              6   \n",
      "4  2020-10-01 00:00:00  40.838928  29.415894  sxkbm6              6   \n",
      "\n",
      "   MAXIMUM_SPEED  AVERAGE_SPEED  NUMBER_OF_VEHICLES  \n",
      "0             70             37                   9  \n",
      "1             56             27                  13  \n",
      "2             51             27                  11  \n",
      "3             74             28                  49  \n",
      "4            177             76                 116  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('traffic_density_202010.csv', sep=',')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".csv dosyalar haricinde .xlsx dosyaları da bağlantıdan çekebilmek mümkündür. Bunun için pd.read_excel fonksiyonunu kullanarak, argüman oalrak bağlantı adresini kullanacağız. İstanbul Büyükşehir Belediyesi Açık Veri Portalı'nda sunulan İtfaiye Konum Verileri excel dosyasını (https://data.ibb.gov.tr/dataset/itfaiye-istasyonlari-konum-bilgileri/resource/c611b9a1-8a1a-44a9-816b-eb6dfcd37c42) kullanalım. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Metadata_TR', 'istasyonlar', 'müfrezeler'])\n"
     ]
    }
   ],
   "source": [
    "# pandas kütüphanesini yükleyelim. \n",
    "import pandas as pd\n",
    "\n",
    "# Bağlantı adresini oluşturulalım: url\n",
    "url = 'https://data.ibb.gov.tr/dataset/75cd7b09-dafb-41fa-90c9-9c7396a58700/resource/c611b9a1-8a1a-44a9-816b-eb6dfcd37c42/download/itfaiye-konum-verisi.xlsx'\n",
    "\n",
    "# Excel dosyasındaki tüm sayfaları okuyalım: xl\n",
    "xl = pd.read_excel(url, sheet_name=None)\n",
    "\n",
    "# Excel dosyasındaki tüm sayfa isimlerini ekrana verelim.\n",
    "print(xl.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  İstasyon Adı Bulunduğu İlçe  \\\n",
      "0                     Adalar İtfaiye İstasyonu         ADALAR   \n",
      "1  Akpınar Mahallesi Gönüllü İtfaiye İstasyonu     EYÜPSULTAN   \n",
      "2                Akşemsettin İtfaiye İstasyonu  GAZİOSMANPAŞA   \n",
      "3  Alacalı Mahallesi Gönüllü İtfaiye İstasyonu           ŞİLE   \n",
      "4                  Alibeyköy İtfaiye İstasyonu     EYÜPSULTAN   \n",
      "\n",
      "                 Koordinat  \n",
      "0  40.87172994,29.13762931  \n",
      "1  41.27821768,28.80994231  \n",
      "2     41.091980, 28.917401  \n",
      "3  41.18315865,29.45650909  \n",
      "4     41.079838, 28.937221  \n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Excel dosyasındaki ikinci çalışma sayfasının ilk beş satırını ekrana verelim (çalışma sayfası ismini kullanarak)\n",
    "print(xl['istasyonlar'].head())\n",
    "print(type(xl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NumPy ile Sayısal Veri Okuma\n",
    "Eğer veriniz sadece sayılardan oluşuyorsa (örneğin bilimsel ölçümler, koordinatlar), NumPy kütüphanesi oldukça hızlıdır.\n",
    "\n",
    "Örnek: Sadece enlem-boylam verisi içeren `coor.csv` dosyasını okuyalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-11.1215276 -75.3587075]\n",
      " [  3.4802964  97.8120924]\n",
      " [  8.2301756 -80.5549561]\n",
      " [ -7.0848567 111.3947978]\n",
      " [ -6.5951    111.0566   ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dosya_ismi = \"coor.csv\"\n",
    "# delimiter=',' verilerin virgülle ayrıldığını belirtir.\n",
    "veri = np.loadtxt(dosya_ismi, delimiter=',')\n",
    "\n",
    "print(veri[:5]) # İlk 5 satırı görelim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Örnek 2: `credit.txt` dosyasını okurken, sadece belirli sütunları almak ve başlık satırını atlamak isteyebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40017. 11854. 23624. 24944. 24996. 32537. 33251. 12867.  8936. 32053.]\n"
     ]
    }
   ],
   "source": [
    "# skiprows=1: Başlığı atla\n",
    "# usecols=[1]: Sadece 2. sütunu (indeks 1) al\n",
    "kredi_verisi = np.loadtxt('credit.txt', delimiter=';', skiprows=1, usecols=[1])\n",
    "\n",
    "print(kredi_verisi[:10]) # İlk 10 veriyi görelim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pandas ile Veri Çerçeveleri (DataFrames)\n",
    "\n",
    "Veri biliminde en sık kullanılan yapı DataFrame'dir. Sütun isimleri olan, farklı veri tiplerini barındırabilen (Excel tablosu gibi) yapılardır.\n",
    "\n",
    "Örnek: Titanic veri setini (.csv) okuyalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  \\\n",
      "0            1         0       3    male  22.0      1      0   \n",
      "1            2         1       1  female  38.0      1      0   \n",
      "2            3         1       3  female  26.0      0      0   \n",
      "3            4         1       1  female  35.0      1      0   \n",
      "4            5         0       3    male  35.0      0      0   \n",
      "\n",
      "             Ticket     Fare Cabin Embarked  \n",
      "0         A/5 21171   7.2500   NaN        S  \n",
      "1          PC 17599  71.2833   C85        C  \n",
      "2  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3            113803  53.1000  C123        S  \n",
      "4            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# pd.read_csv en sık kullanacağımız fonksiyondur.\n",
    "df_titanic = pd.read_csv('titanic.csv')\n",
    "\n",
    "# .head() fonksiyonu verinin ilk 5 satırını gösterir.\n",
    "print(df_titanic.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Örnek: Netflix veri setini okuyalım ve veri hakkında genel bilgi alalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id      tur                                   baslik  \\\n",
      "0  81145628    Movie  Norm of the North: King Sized Adventure   \n",
      "1  80117401    Movie               Jandino: Whatever it Takes   \n",
      "2  70234439  TV Show                       Transformers Prime   \n",
      "3  80058654  TV Show         Transformers: Robots in Disguise   \n",
      "4  80125979    Movie                             #realityhigh   \n",
      "\n",
      "                   yonetmen  \\\n",
      "0  Richard Finn, Tim Maltby   \n",
      "1                       NaN   \n",
      "2                       NaN   \n",
      "3                       NaN   \n",
      "4          Fernando Lebrija   \n",
      "\n",
      "                                                cast  \\\n",
      "0  Alan Marriott, Andrew Toth, Brian Dobson, Cole...   \n",
      "1                                   Jandino Asporaat   \n",
      "2  Peter Cullen, Sumalee Montano, Frank Welker, J...   \n",
      "3  Will Friedle, Darren Criss, Constance Zimmer, ...   \n",
      "4  Nesta Cooper, Kate Walsh, John Michael Higgins...   \n",
      "\n",
      "                                       ulke     eklenme_tarihi  \\\n",
      "0  United States, India, South Korea, China  September 9, 2019   \n",
      "1                            United Kingdom  September 9, 2016   \n",
      "2                             United States  September 8, 2018   \n",
      "3                             United States  September 8, 2018   \n",
      "4                             United States  September 8, 2017   \n",
      "\n",
      "   gosterim_tarihi   reyting      sure                          listelenme  \\\n",
      "0             2019     TV-PG    90 min  Children & Family Movies, Comedies   \n",
      "1             2016     TV-MA    94 min                     Stand-Up Comedy   \n",
      "2             2013  TV-Y7-FV  1 Season                            Kids' TV   \n",
      "3             2016     TV-Y7  1 Season                            Kids' TV   \n",
      "4             2017     TV-14    99 min                            Comedies   \n",
      "\n",
      "                                            aciklama  \n",
      "0  Before planning an awesome wedding for his gra...  \n",
      "1  Jandino Asporaat riffs on the challenges of ra...  \n",
      "2  With the help of three human allies, the Autob...  \n",
      "3  When a prison ship crash unleashes hundreds of...  \n",
      "4  When nerdy high schooler Dani finally attracts...  \n"
     ]
    }
   ],
   "source": [
    "df_netflix = pd.read_csv('netflix.csv')\n",
    "\n",
    "print(df_netflix.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas DataFrame'ini istediğimiz zaman NumPy dizisine (array) çevirebiliriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[81145628 'Movie' 'Norm of the North: King Sized Adventure'\n",
      "  'Richard Finn, Tim Maltby'\n",
      "  'Alan Marriott, Andrew Toth, Brian Dobson, Cole Howard, Jennifer Cameron, Jonathan Holmes, Lee Tockar, Lisa Durupt, Maya Kay, Michael Dobson'\n",
      "  'United States, India, South Korea, China' 'September 9, 2019' 2019\n",
      "  'TV-PG' '90 min' 'Children & Family Movies, Comedies'\n",
      "  'Before planning an awesome wedding for his grandfather, a polar bear king must take back a stolen artifact from an evil archaeologist first.']\n",
      " [80117401 'Movie' 'Jandino: Whatever it Takes' nan 'Jandino Asporaat'\n",
      "  'United Kingdom' 'September 9, 2016' 2016 'TV-MA' '94 min'\n",
      "  'Stand-Up Comedy'\n",
      "  'Jandino Asporaat riffs on the challenges of raising kids and serenades the audience with a rousing rendition of \"Sex on Fire\" in his comedy show.']\n",
      " [70234439 'TV Show' 'Transformers Prime' nan\n",
      "  'Peter Cullen, Sumalee Montano, Frank Welker, Jeffrey Combs, Kevin Michael Richardson, Tania Gunadi, Josh Keaton, Steve Blum, Andy Pessoa, Ernie Hudson, Daran Norris, Will Friedle'\n",
      "  'United States' 'September 8, 2018' 2013 'TV-Y7-FV' '1 Season'\n",
      "  \"Kids' TV\"\n",
      "  'With the help of three human allies, the Autobots once again protect Earth from the onslaught of the Decepticons and their leader, Megatron.']\n",
      " [80058654 'TV Show' 'Transformers: Robots in Disguise' nan\n",
      "  'Will Friedle, Darren Criss, Constance Zimmer, Khary Payton, Mitchell Whitfield, Stuart Allan, Ted McGinley, Peter Cullen'\n",
      "  'United States' 'September 8, 2018' 2016 'TV-Y7' '1 Season' \"Kids' TV\"\n",
      "  'When a prison ship crash unleashes hundreds of Decepticons on Earth, Bumblebee leads a new Autobot force to protect humankind.']\n",
      " [80125979 'Movie' '#realityhigh' 'Fernando Lebrija'\n",
      "  'Nesta Cooper, Kate Walsh, John Michael Higgins, Keith Powers, Alicia Sanz, Jake Borelli, Kid Ink, Yousef Erakat, Rebekah Graf, Anne Winters, Peter Gilroy, Patrick Davis'\n",
      "  'United States' 'September 8, 2017' 2017 'TV-14' '99 min' 'Comedies'\n",
      "  'When nerdy high schooler Dani finally attracts the interest of her longtime crush, she lands in the cross hairs of his ex, a social media celebrity.']]\n"
     ]
    }
   ],
   "source": [
    "# Sadece ilk 5 satırı okuyup numpy dizisine çevirelim\n",
    "veri_dizisi = df_netflix.head(5).to_numpy()\n",
    "\n",
    "print(type(veri_dizisi))\n",
    "print(veri_dizisi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Excel Dosyalarını Okuma (.xlsx)\n",
    "\n",
    "Excel dosyaları genellikle birden fazla sayfa (sheet) içerir. Pandas ile bunları yönetmek çok kolaydır.\n",
    "\n",
    "Örnek: Dünya Mutluluk Raporu (mutluluk_indeksi.xlsx) dosyasını inceleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sayfalar: ['2019', '2018']\n"
     ]
    }
   ],
   "source": [
    "# Excel dosyasını yükle\n",
    "excel_dosyasi = pd.ExcelFile('mutluluk_indeksi.xlsx')\n",
    "\n",
    "# Sayfa isimlerini gör\n",
    "print(f\"Sayfalar: {excel_dosyasi.sheet_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Belirli bir sayfayı okumak için read_excel veya parse kullanabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Overall rank Country or region  Score  GDP per capita  Social support  \\\n",
      "0             1           Finland   7769          1340.0          1587.0   \n",
      "1             2           Denmark   7600          1383.0          1573.0   \n",
      "2             3            Norway   7554          1488.0          1582.0   \n",
      "3             4           Iceland   7494          1380.0          1624.0   \n",
      "4             5       Netherlands   7488          1396.0          1522.0   \n",
      "\n",
      "   Healthy life expectancy  Freedom to make life choices  Generosity  \\\n",
      "0                    0.986                         0.596       0.153   \n",
      "1                    0.996                         0.592       0.252   \n",
      "2                 1028.000                         0.603       0.271   \n",
      "3                 1026.000                         0.591       0.354   \n",
      "4                    0.999                         0.557       0.322   \n",
      "\n",
      "   Perceptions of corruption  \n",
      "0                      0.393  \n",
      "1                      0.410  \n",
      "2                      0.341  \n",
      "3                      0.118  \n",
      "4                      0.298  \n"
     ]
    }
   ],
   "source": [
    "# '2019' isimli sayfayı okuyalım\n",
    "df_2019 = pd.read_excel('mutluluk_indeksi.xlsx', sheet_name='2019')\n",
    "\n",
    "print(df_2019.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gelişmiş Okuma: Başlık satırını atlayıp, sütun isimlerini kendimiz vererek okuyalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Genel Sıralama         Ülke  Skor  Kişi Başı Gelir  Sosyal Destek  \\\n",
      "0               1      Finland  7769           1340.0         1587.0   \n",
      "1               2      Denmark  7600           1383.0         1573.0   \n",
      "2               3       Norway  7554           1488.0         1582.0   \n",
      "3               4      Iceland  7494           1380.0         1624.0   \n",
      "4               5  Netherlands  7488           1396.0         1522.0   \n",
      "\n",
      "   Sağlıklı Yaşam  Özgürlük  Cömertlik  Yolsuzluk Algısı  \n",
      "0           0.986     0.596      0.153             0.393  \n",
      "1           0.996     0.592      0.252             0.410  \n",
      "2        1028.000     0.603      0.271             0.341  \n",
      "3        1026.000     0.591      0.354             0.118  \n",
      "4           0.999     0.557      0.322             0.298  \n"
     ]
    }
   ],
   "source": [
    "yeni_isimler = ['Genel Sıralama','Ülke', 'Skor', 'Kişi Başı Gelir', \n",
    "                'Sosyal Destek', 'Sağlıklı Yaşam', 'Özgürlük', \n",
    "                'Cömertlik', 'Yolsuzluk Algısı']\n",
    "\n",
    "# sheet_name=0 -> İlk sayfayı ifade eder (indeks ile)\n",
    "df_ozel = pd.read_excel('mutluluk_indeksi.xlsx', sheet_name=0, header=0, names=yeni_isimler)\n",
    "\n",
    "print(df_ozel.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. İstatistiksel Veri Dosyalarını Okuma (SAS ve Stata)\n",
    "\n",
    "Eskiden bu dosyalar için ek kütüphaneler gerekirdi. Artık Pandas bunları yerleşik olarak okuyabilir.\n",
    "\n",
    "SAS Dosyası Okuma (.sas7bdat):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INC88  TAX88  INC89  TAX89\n",
      "0  9.215  1.643  9.518  2.125\n",
      "1  2.047  0.413  2.068  0.565\n",
      "2  9.989  1.752  9.992  2.221\n",
      "3  8.321  1.408  8.515  1.905\n",
      "4  4.588  0.838  4.389  0.943\n"
     ]
    }
   ],
   "source": [
    "# Eskiden 'sas7bdat' kütüphanesi kullanılırdı, şimdi Pandas yeterli.\n",
    "df_sas = pd.read_sas('tax.sas7bdat')\n",
    "\n",
    "# SAS dosyalarındaki metinler bazen byte formatında gelir, okurken decode gerekebilir ama temel okuma şöyledir:\n",
    "print(df_sas.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stata Dosyası Okuma (.dta):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   inc88  tax88  inc89  tax89\n",
      "0  9.215  1.643  9.518  2.125\n",
      "1  2.047  0.413  2.068  0.565\n",
      "2  9.989  1.752  9.992  2.221\n",
      "3  8.321  1.408  8.515  1.905\n",
      "4  4.588  0.838  4.389  0.943\n"
     ]
    }
   ],
   "source": [
    "df_stata = pd.read_stata('tax.dta')\n",
    "print(df_stata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. MATLAB Dosyalarını Okuma (.mat)\n",
    "\n",
    "MATLAB verileri genellikle .mat formatındadır. Bunu okumak için SciPy kütüphanesi standarttır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'annotations'])\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "\n",
    "mat_verisi = scipy.io.loadmat('cars_train_annos.mat')\n",
    "\n",
    "print(type(mat_verisi))\n",
    "print(mat_verisi.keys()) # Dosya içindeki değişkenleri görelim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Web Üzerinden Doğrudan Veri Okuma\n",
    "\n",
    "Veriyi bilgisayara indirmeden, doğrudan internet bağlantısı (URL) ile Pandas içine çekebiliriz. Bu yöntem kodunuzu çok daha temiz hale getirir.\n",
    "\n",
    "Örnek 1: İBB Trafik Verisi (.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             DATE_TIME   LATITUDE  LONGITUDE GEOHASH  MINIMUM_SPEED  \\\n",
      "0  2020-10-01 00:00:00  41.195984  28.767700  sxk6qe             18   \n",
      "1  2020-10-01 00:00:00  41.009216  29.042358  sxk9kc              9   \n",
      "2  2020-10-01 00:00:00  40.970764  29.075317  sxk9jd              9   \n",
      "3  2020-10-01 00:00:00  41.069641  28.888550  sxk99k              6   \n",
      "4  2020-10-01 00:00:00  40.838928  29.415894  sxkbm6              6   \n",
      "\n",
      "   MAXIMUM_SPEED  AVERAGE_SPEED  NUMBER_OF_VEHICLES  \n",
      "0             70             37                   9  \n",
      "1             56             27                  13  \n",
      "2             51             27                  11  \n",
      "3             74             28                  49  \n",
      "4            177             76                 116  \n"
     ]
    }
   ],
   "source": [
    "url_csv = 'https://data.ibb.gov.tr/dataset/3ee6d744-5da2-40c8-9cd6-0e3e41f1928f/resource/949d4a3b-91d2-4c56-b82f-4ef081e39c45/download/traffic_density_202010.csv'\n",
    "\n",
    "# URL'i sanki dosya yoluymuş gibi veriyoruz\n",
    "df_trafik = pd.read_csv(url_csv)\n",
    "\n",
    "print(df_trafik.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Örnek 2: İBB İtfaiye Verisi (.xlsx)\n",
    "\n",
    "Excel dosyalarını da doğrudan linkten okuyabiliriz. sheet_name=None parametresi, dosyadaki tüm sayfaları bir sözlük (dictionary) olarak okumamızı sağlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Metadata_TR', 'istasyonlar', 'müfrezeler'])\n",
      "                                  İstasyon Adı Bulunduğu İlçe  \\\n",
      "0                     Adalar İtfaiye İstasyonu         ADALAR   \n",
      "1  Akpınar Mahallesi Gönüllü İtfaiye İstasyonu     EYÜPSULTAN   \n",
      "2                Akşemsettin İtfaiye İstasyonu  GAZİOSMANPAŞA   \n",
      "3  Alacalı Mahallesi Gönüllü İtfaiye İstasyonu           ŞİLE   \n",
      "4                  Alibeyköy İtfaiye İstasyonu     EYÜPSULTAN   \n",
      "\n",
      "                 Koordinat  \n",
      "0  40.87172994,29.13762931  \n",
      "1  41.27821768,28.80994231  \n",
      "2     41.091980, 28.917401  \n",
      "3  41.18315865,29.45650909  \n",
      "4     41.079838, 28.937221  \n"
     ]
    }
   ],
   "source": [
    "url_excel = 'https://data.ibb.gov.tr/dataset/75cd7b09-dafb-41fa-90c9-9c7396a58700/resource/c611b9a1-8a1a-44a9-816b-eb6dfcd37c42/download/itfaiye-konum-verisi.xlsx'\n",
    "\n",
    "# Tüm sayfaları oku\n",
    "itfaiye_verisi = pd.read_excel(url_excel, sheet_name=None)\n",
    "\n",
    "# Sayfa isimlerini görelim\n",
    "print(itfaiye_verisi.keys())\n",
    "\n",
    "# 'istasyonlar' sayfasını ekrana yazdıralım\n",
    "print(itfaiye_verisi['istasyonlar'].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
